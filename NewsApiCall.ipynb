{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a63f8df1-ad62-4341-b8ea-db57f820b1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "import yfinance as yf\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "378ad563-b15a-4402-9528-3cdb5e3f147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_finnhub_news(ticker):\n",
    "    load_dotenv()  # Load environment variables from .env file\n",
    "\n",
    "    FINNHUB_API_KEY = os.getenv(\"FINNHUB_API_KEY\")\n",
    "    if not FINNHUB_API_KEY:\n",
    "        print(\"Finnhub API key is missing.\")\n",
    "        return []\n",
    "\n",
    "    to_date = datetime.now().strftime('%Y-%m-%d')\n",
    "    from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "\n",
    "    url = f\"https://finnhub.io/api/v1/company-news?symbol={ticker}&from={from_date}&to={to_date}&token={FINNHUB_API_KEY}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        articles = []\n",
    "\n",
    "        for item in data[:20]:\n",
    "            raw_title = item.get('headline', '')\n",
    "            raw_content = item.get('summary', '')\n",
    "\n",
    "            title = raw_title.lower() if raw_title else ''\n",
    "            content = raw_content.lower() if raw_content else ''\n",
    "            ticker_lower = ticker.lower()\n",
    "\n",
    "            # Only include if ticker is found in title or content\n",
    "            if ticker_lower in title or ticker_lower in content:\n",
    "                try:\n",
    "                    readable_date = datetime.fromtimestamp(item['datetime']).strftime('%Y-%m-%d %H:%M:%S')\n",
    "                except (KeyError, TypeError, ValueError):\n",
    "                    readable_date = \"Unknown\"\n",
    "\n",
    "                articles.append({\n",
    "                    'date': readable_date,\n",
    "                    'title': raw_title,\n",
    "                    'content': raw_content,\n",
    "                    'source': 'Finnhub',\n",
    "                    'url': item.get('url', '')\n",
    "                })\n",
    "\n",
    "            if len(articles) == 20:\n",
    "                break\n",
    "\n",
    "        return articles\n",
    "\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching Finnhub news for {ticker}: {str(e)}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1173fbea-4e38-46f4-9200-57af485e72ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_relevant(title, content, ticker):\n",
    "    title = str(title) if title is not None else \"\"\n",
    "    content = str(content) if content is not None else \"\"\n",
    "    text = (title + \" \" + content).lower()\n",
    "    ticker = ticker.lower()\n",
    "    return ticker in text or 'stock' in text or 'share' in text or 'market' in text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af6e751a-f6e0-4342-903a-41a78b0d374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess the text\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8154c9b-b439-45dc-9236-89980286538c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_newsapi_news(ticker):\n",
    "    load_dotenv()\n",
    "    NEWS_API_KEY = os.getenv(\"NEWS_API_KEY\")\n",
    "    if not NEWS_API_KEY:\n",
    "        print(\"NewsAPI key is missing.\")\n",
    "        return []\n",
    "\n",
    "    newsapi = NewsApiClient(api_key=NEWS_API_KEY)\n",
    "\n",
    "    try:\n",
    "        query = f'\"{ticker}\" AND (stock OR shares OR earnings OR finance OR market)'\n",
    "\n",
    "        from_date = (datetime.now() - timedelta(days=7)).strftime('%Y-%m-%d')\n",
    "        to_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "        response = newsapi.get_everything(q=query,\n",
    "                                          language='en',\n",
    "                                          sort_by='publishedAt',\n",
    "                                          from_param=from_date,\n",
    "                                          to=to_date,\n",
    "                                          page_size=20)\n",
    "\n",
    "        articles = []\n",
    "\n",
    "        for item in response['articles']:\n",
    "            raw_title = item.get('title', '')\n",
    "            raw_description = item.get('description', '')\n",
    "\n",
    "            title = raw_title.lower() if raw_title else ''\n",
    "            content = raw_description.lower() if raw_description else ''\n",
    "\n",
    "            # Define keyword list including ticker\n",
    "            keywords = [\n",
    "                'stock', 'share', 'shares', 'earnings', 'revenue', 'profit', 'loss',\n",
    "                'acquisition', 'merger', 'ipo', 'buyback', 'dividend', 'forecast', 'guidance',\n",
    "                'market', 'finance', 'financial', 'investment', 'investor', 'trading',\n",
    "                'company', 'results', 'quarter', 'report', 'business', 'valuation', 'layoffs',\n",
    "                'sec', 'ceo', 'cfo', 'announcement', 'strategy', 'expansion',\n",
    "                ticker.lower()\n",
    "            ]\n",
    "\n",
    "            # OR condition: ticker in title/content OR any keyword in title/content\n",
    "            if ticker.lower() in content or ticker.lower() in title or \\\n",
    "               any(kw in content or kw in title for kw in keywords):\n",
    "\n",
    "                try:\n",
    "                    published_at = datetime.strptime(item['publishedAt'], '%Y-%m-%dT%H:%M:%SZ')\n",
    "                    formatted_date = published_at.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                except (KeyError, ValueError):\n",
    "                    formatted_date = \"Unknown\"\n",
    "\n",
    "                # Optional: Clean text if you have a clean_text() function\n",
    "                cleaned_title = clean_text(raw_title) if raw_title else ''\n",
    "                cleaned_content = clean_text(raw_description) if raw_description else ''\n",
    "\n",
    "                articles.append({\n",
    "                    'ticker': ticker,\n",
    "                    'date': formatted_date,\n",
    "                    'title': raw_title,\n",
    "                    'content': raw_description,\n",
    "                    'cleaned_title': cleaned_title,\n",
    "                    'cleaned_content': cleaned_content,\n",
    "                    'source': 'NewsAPI',\n",
    "                    'url': item.get('url', '')\n",
    "                })\n",
    "\n",
    "            if len(articles) == 20:\n",
    "                break\n",
    "\n",
    "        return articles\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching NewsAPI news for {ticker}: {str(e)}\")\n",
    "        return []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ca26b3b-b54d-4264-91a5-ab20f1b6a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_and_preprocess_data(ticker):\n",
    "    all_data = []\n",
    "    print(f\"Fetching news for {ticker}...\")\n",
    "    newsapi_articles = fetch_newsapi_news(ticker)\n",
    "    finnhub_articles = fetch_finnhub_news(ticker)\n",
    "    all_articles = newsapi_articles + finnhub_articles\n",
    "    if not all_articles:\n",
    "        print(f\"No articles found for {ticker}\")\n",
    "        return []\n",
    "    for article in all_articles:\n",
    "        title = article.get('title')\n",
    "        content = article.get('content')\n",
    "        date = article.get('date')\n",
    "        source = article.get('source')\n",
    "        url = article.get('url')\n",
    "\n",
    "        # Skip articles with missing essential data\n",
    "        if not all([title, content, date, source, url]):\n",
    "            print(f\"Skipping article with missing data for {ticker}\")\n",
    "            continue\n",
    "\n",
    "        if not is_relevant(title, content, ticker):\n",
    "            continue\n",
    "        cleaned_title = clean_text(title)\n",
    "        cleaned_content = clean_text(content)\n",
    "        all_data.append({\n",
    "            'ticker': ticker,\n",
    "            'date': date,\n",
    "            'title': title,\n",
    "            'content': content,\n",
    "            'cleaned_title': cleaned_title,\n",
    "            'cleaned_content': cleaned_content,\n",
    "            'source': source,\n",
    "            'url': url\n",
    "        })\n",
    "        # Add a small delay to avoid overwhelming servers\n",
    "        time.sleep(0.1)\n",
    "    return all_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41db0e35-c4bb-43cb-90e3-634c8be7969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def article_content_sentiment(stock_data):\n",
    "    pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")  # Load pretrained model\n",
    "\n",
    "    def sentiment_score(sentiment):\n",
    "        label = sentiment['label'].lower()\n",
    "        if label == 'positive':\n",
    "            return 1\n",
    "        elif label == 'negative':\n",
    "            return -1\n",
    "        else:  # neutral or other\n",
    "            return 0\n",
    "\n",
    "    avg_score = 0\n",
    "    article_titles = []\n",
    "    for article in stock_data:\n",
    "        cleaned_title = article['cleaned_title']\n",
    "        article_titles.append(cleaned_title)\n",
    "        cleaned_content = article['cleaned_content']\n",
    "\n",
    "        sentiment_title = pipe(cleaned_title)[0]\n",
    "        sentiment_content = pipe(cleaned_content)[0]\n",
    "\n",
    "        title_sent = sentiment_score(sentiment_title)\n",
    "        content_sent = sentiment_score(sentiment_content)\n",
    "\n",
    "        avg_article_score = (title_sent + content_sent) / 2\n",
    "\n",
    "        # print(f\"{cleaned_title} Title sentiment: {title_sent}\\n\")\n",
    "        # print(f\"{cleaned_content} Content sentiment: {content_sent}\\n\")\n",
    "        # print(f\"Average article sentiment: {avg_article_score}\\n\")\n",
    "\n",
    "        avg_score += avg_article_score\n",
    "\n",
    "    overall_avg_score = avg_score / len(stock_data) if stock_data else 0\n",
    "    # print(f\"Overall average sentiment score: {overall_avg_score}\")\n",
    "    return overall_avg_score , article_titles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fedd5e9e-2b52-4bdf-ad6c-561bd9b7c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    ticker_or_title = input(\"Enter Stock Ticker (Or company name (ticker more accurate)): \")\n",
    "    stock_data = collect_and_preprocess_data(ticker_or_title)\n",
    "    \n",
    "    final_score, article_titles = article_content_sentiment(stock_data)\n",
    "    \n",
    "    return {\n",
    "        \"ticker\": ticker_or_title,\n",
    "        \"score\": final_score,\n",
    "        \"news_titles\": article_titles\n",
    "    }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
